<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>Codebook:Getting and Cleaning Data</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>





</head>

<body>
<h1>Codebook:Getting and Cleaning Data</h1>

<h2>Variables</h2>

<ul>
<li><p><code>afulldata</code> - Data frame, 10299 observations, 564 variables,present in Complete_data.txt or Complete_data.csv</p>

<ul>
<li><code>ActivityID</code> - The ID of the activity performed. Values from 1:30</li>
<li><code>ActivityName</code> - Labels naming the activity, as per activity_labels.txt. Values: LAYING SITTING STANDING WALKING WALKING_DOWNSTAIRS WALKING_UPSTAIRS</li>
<li><code>SubjectID</code> - ID number of the subject. Values from 1:30</li>
<li>The above values represent whose values of were recorded.</li>
<li>The remaining 561 columns are numeric values of the features, named as           described in the given data. Features are normalized and bounded within values [-1,1].</li>
</ul></li>
<li><p><code>acntdata</code> - Data frame, 10299 observations, 69 variables, present in tidy_data.txt or tidy_data.csv</p>

<ul>
<li><code>ActivityID</code> - The ID of the activity performed. Values from 1:30</li>
<li><code>ActivityName</code> - Labels naming the activity, as per activity_labels.txt. Values: LAYING SITTING STANDING WALKING WALKING_DOWNSTAIRS WALKING_UPSTAIRS</li>
<li><code>SubjectID</code> - ID number of the subject. Values from 1:30</li>
<li> The remaining 66 columns correspond to the numeric values of features containing <code>-mean()</code> or <code>-std()</code> in their names. Their names have been cleaned up to be self-explanatory. Features are normalized and bounded within values [-1,1].</li>
</ul></li>
</ul>

<h2>About the Variables and Experimental Used</h2>

<p>The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain signals (prefix &#39;t&#39; to denote time) were captured at a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz. </p>

<p>Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). </p>

<p>Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. (Note the &#39;f&#39; to indicate frequency domain signals). </p>

<p>These signals were used to estimate variables of the feature vector for each pattern:<br/>
&#39;-XYZ&#39; is used to denote 3-axial signals in the X, Y and Z directions.</p>

<p>tBodyAcc-XYZ,
tGravityAcc-XYZ,
tBodyAccJerk-XYZ,
tBodyGyro-XYZ,
tBodyGyroJerk-XYZ,
tBodyAccMag,
tGravityAccMag,
tBodyAccJerkMag,
tBodyGyroMag,
tBodyGyroJerkMag,
fBodyAcc-XYZ,
fBodyAccJerk-XYZ,
fBodyGyro-XYZ,
fBodyAccMag,
fBodyAccJerkMag,
fBodyGyroMag,
fBodyGyroJerkMag</p>

<p>We are calculating mean and standard deviation for the above mentioned variable.
Features are normalized and bounded within [-1,1].</p>

<h2>Summary of process followed in run_analysis</h2>

<pre><code>*Column bind all the test data: x,y subject to get `testdata`
*Column bind all the train data: x,y subject to get `traindata`
*Row binded the above data `fulldata`
*Merge this data with activity_labels data to get a complete dataset with every activity and renaming column names of this complete dataset with the help of features dataset. The complete dataset is called `afulldata`
*Creating a dataset `reddata` having only mean and std features with `ActivityID`,`ActivityName` and `SubjectID`
*Creating required tidy dataset `acntdata` with the necessary processing
*Writing the necessary tables :
    &gt;`afulldata` in `Complete_data.txt` and `Complete_data.csv` 
    &gt;`acntdata`  in `tidy_data.txt` and `tidy_data.csv`
</code></pre>

</body>

</html>

